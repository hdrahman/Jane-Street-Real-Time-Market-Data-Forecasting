{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d799e85-9b27-48c5-80a7-44f3b65ae782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl #resave only feature based files\n",
    "\n",
    "# Define file paths\n",
    "data_path = '/home/jupyter/data/jane-street/test.parquet'\n",
    "output_path = '/home/jupyter/data/jane-street/test_cleaned.parquet'\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "data = pl.read_parquet(data_path)\n",
    "\n",
    "# Display all columns to identify responders\n",
    "print(\"Columns in dataset:\", data.columns)\n",
    "\n",
    "# Define columns to drop (all responders)\n",
    "columns_to_drop = [col for col in data.columns if \"responder\" in col]\n",
    "\n",
    "# Drop the unnecessary responder columns\n",
    "print(f\"Dropping {len(columns_to_drop)} responder columns...\")\n",
    "cleaned_data = data.drop(columns_to_drop)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_data.write_parquet(output_path, compression=\"snappy\")\n",
    "print(f\"Cleaned dataset saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c062dd1b-62b1-4a65-92a7-32b770e2be56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Parquet datasets for external memory usage...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jupyter/data/external_memory_test.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Parquet datasets for external memory usage...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mread_parquet(test_path)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Step 2: Prepare DMatrix with Parquet using Explicit Labels and Weights\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/_utils/deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/_utils/deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/io/parquet/functions.py:241\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, schema, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, credential_provider, retries, use_pyarrow, pyarrow_options, memory_map, include_file_paths, allow_missing_columns)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m         lf \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mselect(columns)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/lazyframe/frame.py:2029\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2028\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import polars as pl  #get rid of unneeded features and resave\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "# Weighted R² evaluation metric\n",
    "def weighted_r2_score(y_true, y_pred, weights):\n",
    "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "    denominator = np.sum(weights * y_true ** 2)\n",
    "    r2 = 1 - (numerator / denominator)\n",
    "    return r2\n",
    "\n",
    "# Step 1: Load dataset lazily\n",
    "print(\"Loading dataset lazily...\")\n",
    "data_lazy = pl.scan_parquet(\"/home/jupyter/data/XGFeatures_partitioned/\")\n",
    "\n",
    "# Step 2: Chunked Feature Importance Calculation (Manual Chunking)\n",
    "feature_importance_agg = {}\n",
    "chunk_size = 500_000  # Define chunk size for memory control\n",
    "total_rows = data_lazy.select(pl.len()).collect().item()\n",
    "num_chunks = total_rows // chunk_size + 1\n",
    "\n",
    "print(f\"Calculating feature importance using {num_chunks} chunks...\")\n",
    "for i in range(num_chunks):\n",
    "    chunk = data_lazy.slice(i * chunk_size, chunk_size).collect()\n",
    "    X_chunk = chunk.select(pl.exclude([\"responder_6\", \"date_id\", \"time_id\", \"weight\"]))\n",
    "    y_chunk = chunk[\"responder_6\"]\n",
    "    weights_chunk = chunk[\"weight\"]\n",
    "\n",
    "    # Train a temporary XGBoost model on this chunk\n",
    "    dtrain_chunk = xgb.DMatrix(X_chunk.to_numpy(), label=y_chunk.to_numpy(), weight=weights_chunk.to_numpy())\n",
    "\n",
    "    params_temp = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 4,\n",
    "        \"device\": \"cuda\",  # Proper GPU usage\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": 42\n",
    "    }\n",
    "    temp_model = xgb.train(params_temp, dtrain_chunk, num_boost_round=20)\n",
    "\n",
    "    # Correct feature extraction based on actual column names\n",
    "    importance = temp_model.get_score(importance_type=\"weight\")\n",
    "    column_names = X_chunk.columns\n",
    "    for feature_name, score in importance.items():\n",
    "        try:\n",
    "            feature_idx = int(feature_name[1:])  # Extract the feature number\n",
    "            actual_feature_name = column_names[feature_idx]\n",
    "            feature_importance_agg[actual_feature_name] = feature_importance_agg.get(actual_feature_name, 0) + score\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "\n",
    "# Step 3: Select Top 30 Features with Correct Column Handling\n",
    "sorted_features = sorted(feature_importance_agg.items(), key=lambda x: x[1], reverse=True)\n",
    "top_features = [f[0] for f in sorted_features[:30]]\n",
    "print(f\"Selected Top 30 Features: {top_features}\")\n",
    "\n",
    "# Step 4: Filter the entire dataset using the corrected top 30 features\n",
    "print(\"Filtering dataset with top features...\")\n",
    "filtered_data = data_lazy.select(top_features + [\"responder_6\", \"weight\", \"date_id\", \"time_id\"]).collect()\n",
    "\n",
    "# Step 5: Save Filtered Dataset for External Memory\n",
    "train_path = \"/home/jupyter/data/external_memory_train.parquet\"\n",
    "test_path = \"/home/jupyter/data/external_memory_test.parquet\"\n",
    "\n",
    "split_date = filtered_data[\"date_id\"].quantile(0.8)\n",
    "\n",
    "train_data = filtered_data.filter(pl.col(\"date_id\") < split_date)\n",
    "test_data = filtered_data.filter(pl.col(\"date_id\") >= split_date)\n",
    "\n",
    "train_data.write_parquet(train_path)\n",
    "test_data.write_parquet(test_path)\n",
    "print(\"Filtered datasets saved for external memory training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92c30d8-afd6-4916-89f2-5e13251a3beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Parquet datasets for external memory usage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-04 05:56:48,439] A new study created in memory with name: no-name-03234175-805f-46d7-b1e7-d0cebc109e51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Optuna study...\n",
      "Running Bayesian optimization with Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-04 05:58:52,618] Trial 0 finished with value: -0.7341050505638123 and parameters: {'learning_rate': 0.2569775197414957, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9977270835704746, 'colsample_bytree': 0.9414119024295959, 'reg_lambda': 0.15183940804495094, 'reg_alpha': 0.6968014803915679}. Best is trial 0 with value: -0.7341050505638123.\n",
      "[I 2025-01-04 06:00:46,333] Trial 1 finished with value: -0.6965613067150116 and parameters: {'learning_rate': 0.2918470709430596, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.99083237194199, 'colsample_bytree': 0.9121588042277565, 'reg_lambda': 0.26192821258898086, 'reg_alpha': 0.4096982819263813}. Best is trial 1 with value: -0.6965613067150116.\n",
      "[I 2025-01-04 06:02:41,512] Trial 2 finished with value: -0.7237693965435028 and parameters: {'learning_rate': 0.27275364611760267, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9354699133591238, 'colsample_bytree': 0.9377692899879054, 'reg_lambda': 0.6576882026622826, 'reg_alpha': 0.2511860246478515}. Best is trial 1 with value: -0.6965613067150116.\n",
      "[I 2025-01-04 06:04:36,294] Trial 3 finished with value: -0.7357716262340546 and parameters: {'learning_rate': 0.2601777379288195, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.962449331963081, 'colsample_bytree': 0.9080288843176076, 'reg_lambda': 0.6960796440648166, 'reg_alpha': 0.3143462751007233}. Best is trial 1 with value: -0.6965613067150116.\n",
      "[I 2025-01-04 06:06:30,819] Trial 4 finished with value: -0.7384775280952454 and parameters: {'learning_rate': 0.2760138719725315, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9702267520311851, 'colsample_bytree': 0.905759437039524, 'reg_lambda': 0.20683368529758686, 'reg_alpha': 0.5693459621393185}. Best is trial 1 with value: -0.6965613067150116.\n",
      "[I 2025-01-04 06:08:24,946] Trial 5 finished with value: -0.699577271938324 and parameters: {'learning_rate': 0.258351243545971, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9828069901983257, 'colsample_bytree': 0.9300453893479727, 'reg_lambda': 0.7768902827856686, 'reg_alpha': 0.864737394631884}. Best is trial 1 with value: -0.6965613067150116.\n",
      "[I 2025-01-04 06:10:04,163] Trial 6 finished with value: -0.6711702048778534 and parameters: {'learning_rate': 0.2824521955260779, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9748729822354355, 'colsample_bytree': 0.9213094046023811, 'reg_lambda': 0.6973052328811126, 'reg_alpha': 0.41114432346208596}. Best is trial 6 with value: -0.6711702048778534.\n",
      "[I 2025-01-04 06:11:58,333] Trial 7 finished with value: -0.68661829829216 and parameters: {'learning_rate': 0.26914235969382816, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.984884485341564, 'colsample_bytree': 0.999060576105195, 'reg_lambda': 0.7956093266961863, 'reg_alpha': 0.27065583846242797}. Best is trial 6 with value: -0.6711702048778534.\n",
      "[I 2025-01-04 06:13:38,383] Trial 8 finished with value: -0.7344848215579987 and parameters: {'learning_rate': 0.26716257334741583, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9236176166567183, 'colsample_bytree': 0.9198866543865521, 'reg_lambda': 0.7766513266921419, 'reg_alpha': 0.38631897735969895}. Best is trial 6 with value: -0.6711702048778534.\n",
      "[I 2025-01-04 06:15:17,782] Trial 9 finished with value: -0.7023866176605225 and parameters: {'learning_rate': 0.28413763461940084, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9431320152941469, 'colsample_bytree': 0.972635149909747, 'reg_lambda': 0.7404985950474976, 'reg_alpha': 0.3078588696475139}. Best is trial 6 with value: -0.6711702048778534.\n",
      "[I 2025-01-04 06:16:56,262] Trial 10 finished with value: -0.7014114558696747 and parameters: {'learning_rate': 0.29708983182945764, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9042963587457442, 'colsample_bytree': 0.9624898255124997, 'reg_lambda': 0.46338461935029535, 'reg_alpha': 0.00555811954427371}. Best is trial 6 with value: -0.6711702048778534.\n",
      "[I 2025-01-04 06:18:35,261] Trial 11 finished with value: -0.7116134762763977 and parameters: {'learning_rate': 0.28248957279476755, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9698874476003857, 'colsample_bytree': 0.9880284764754517, 'reg_lambda': 0.9651629741270589, 'reg_alpha': 0.11602412707487986}. Best is trial 6 with value: -0.6711702048778534.\n",
      "[I 2025-01-04 06:20:15,066] Trial 12 finished with value: -0.7257639467716217 and parameters: {'learning_rate': 0.2666496447045166, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9792200068104029, 'colsample_bytree': 0.9543821768281275, 'reg_lambda': 0.49202663875217, 'reg_alpha': 0.5768625276869522}. Best is trial 6 with value: -0.6711702048778534.\n",
      "[I 2025-01-04 06:21:54,085] Trial 13 finished with value: -0.6432170569896698 and parameters: {'learning_rate': 0.283610478180405, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9531626442697243, 'colsample_bytree': 0.992284782449991, 'reg_lambda': 0.9780235889501963, 'reg_alpha': 0.1614920195096206}. Best is trial 13 with value: -0.6432170569896698.\n",
      "[I 2025-01-04 06:23:33,550] Trial 14 finished with value: -0.7126374542713165 and parameters: {'learning_rate': 0.2856988372143362, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9581730964021952, 'colsample_bytree': 0.9759156113375305, 'reg_lambda': 0.9695657175152798, 'reg_alpha': 0.10894574896258286}. Best is trial 13 with value: -0.6432170569896698.\n",
      "[I 2025-01-04 06:25:13,241] Trial 15 finished with value: -0.6822099387645721 and parameters: {'learning_rate': 0.27792711847490686, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9503239291808793, 'colsample_bytree': 0.929870093270783, 'reg_lambda': 0.581047487609366, 'reg_alpha': 0.1528039740749788}. Best is trial 13 with value: -0.6432170569896698.\n",
      "[I 2025-01-04 06:26:52,003] Trial 16 finished with value: -0.6097070574760437 and parameters: {'learning_rate': 0.2912355107178364, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9411675406829799, 'colsample_bytree': 0.9508595022735182, 'reg_lambda': 0.34240392305481115, 'reg_alpha': 0.47070840020071786}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:28:30,432] Trial 17 finished with value: -0.7331017255783081 and parameters: {'learning_rate': 0.29131810816080916, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9341462146693248, 'colsample_bytree': 0.9995113098806887, 'reg_lambda': 0.00551713240555135, 'reg_alpha': 0.7547416228403228}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:30:09,118] Trial 18 finished with value: -0.687843918800354 and parameters: {'learning_rate': 0.2973174610678548, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9175131723383685, 'colsample_bytree': 0.9787401735121266, 'reg_lambda': 0.38009053445309104, 'reg_alpha': 0.5149982055446592}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:31:48,024] Trial 19 finished with value: -0.7026135623455048 and parameters: {'learning_rate': 0.29003862440076833, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9506842394731188, 'colsample_bytree': 0.9552704918772348, 'reg_lambda': 0.33103868901238453, 'reg_alpha': 0.650421205586367}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:33:27,448] Trial 20 finished with value: -0.7346222400665283 and parameters: {'learning_rate': 0.28796877421352035, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9216664909919767, 'colsample_bytree': 0.9688809285811901, 'reg_lambda': 0.8885730333029038, 'reg_alpha': 0.007393512842798822}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:35:07,109] Trial 21 finished with value: -0.7143469750881195 and parameters: {'learning_rate': 0.28234975323385475, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9640517558286542, 'colsample_bytree': 0.9458210674999383, 'reg_lambda': 0.5906509442088589, 'reg_alpha': 0.42571893414845907}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:36:45,929] Trial 22 finished with value: -0.7126637399196625 and parameters: {'learning_rate': 0.27931056574926255, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9406738211609053, 'colsample_bytree': 0.9233286008415854, 'reg_lambda': 0.8858702985802054, 'reg_alpha': 0.1997448676957871}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:38:24,992] Trial 23 finished with value: -0.7168506681919098 and parameters: {'learning_rate': 0.2936848443871438, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9544989803155041, 'colsample_bytree': 0.988384610168339, 'reg_lambda': 0.38405221716279214, 'reg_alpha': 0.4687117168912773}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:40:04,008] Trial 24 finished with value: -0.7281191051006317 and parameters: {'learning_rate': 0.28672005379155985, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9306686187495355, 'colsample_bytree': 0.9015555122581408, 'reg_lambda': 0.09608837010757987, 'reg_alpha': 0.9633394797958255}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:41:42,963] Trial 25 finished with value: -0.6398290991783142 and parameters: {'learning_rate': 0.27315266192168985, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9753018128529313, 'colsample_bytree': 0.9169517905531681, 'reg_lambda': 0.5647179194334994, 'reg_alpha': 0.37004033259876423}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:43:21,953] Trial 26 finished with value: -0.7255518734455109 and parameters: {'learning_rate': 0.27346573984391986, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9436707244589528, 'colsample_bytree': 0.9630738225471085, 'reg_lambda': 0.5669746337021889, 'reg_alpha': 0.3445395120065904}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:45:01,954] Trial 27 finished with value: -0.7279263734817505 and parameters: {'learning_rate': 0.2512415809246272, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9094893510783365, 'colsample_bytree': 0.9333849967610816, 'reg_lambda': 0.42922277921839436, 'reg_alpha': 0.20337133191130513}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:46:40,800] Trial 28 finished with value: -0.7297461926937103 and parameters: {'learning_rate': 0.29918716642740595, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9622935964823957, 'colsample_bytree': 0.9861138277299051, 'reg_lambda': 0.2513137948635871, 'reg_alpha': 0.5093107302092683}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:48:19,871] Trial 29 finished with value: -0.7275621891021729 and parameters: {'learning_rate': 0.26302783884812014, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9454771326380679, 'colsample_bytree': 0.9458142243185897, 'reg_lambda': 0.08360037235962442, 'reg_alpha': 0.6854887630227829}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:49:59,366] Trial 30 finished with value: -0.7366021573543549 and parameters: {'learning_rate': 0.2790730908511544, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9979190687091443, 'colsample_bytree': 0.9142864342348465, 'reg_lambda': 0.3149734935914589, 'reg_alpha': 0.7715469764170382}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:51:38,287] Trial 31 finished with value: -0.7109650373458862 and parameters: {'learning_rate': 0.28128725211178524, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9719156728539794, 'colsample_bytree': 0.9190155789421313, 'reg_lambda': 0.6432759557930336, 'reg_alpha': 0.6107189318553559}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:53:17,108] Trial 32 finished with value: -0.7069864273071289 and parameters: {'learning_rate': 0.29369529008254724, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9739789767443022, 'colsample_bytree': 0.9245155244729142, 'reg_lambda': 0.5275629079485595, 'reg_alpha': 0.45393194298155265}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:54:55,793] Trial 33 finished with value: -0.7337469458580017 and parameters: {'learning_rate': 0.27562002853588474, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9888947219231439, 'colsample_bytree': 0.9394104000244515, 'reg_lambda': 0.8381755232327335, 'reg_alpha': 0.39688867296351305}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:56:50,218] Trial 34 finished with value: -0.7362157702445984 and parameters: {'learning_rate': 0.2712682682966696, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9764733732691432, 'colsample_bytree': 0.9104466451011296, 'reg_lambda': 0.6664209628541395, 'reg_alpha': 0.2489589608976846}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 06:58:29,560] Trial 35 finished with value: -0.6914727091789246 and parameters: {'learning_rate': 0.28852651080506914, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.965630167195148, 'colsample_bytree': 0.9147734845297454, 'reg_lambda': 0.7000726440898831, 'reg_alpha': 0.36965489681030816}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:00:23,967] Trial 36 finished with value: -0.739000529050827 and parameters: {'learning_rate': 0.28568868675410736, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9910194419250831, 'colsample_bytree': 0.9352849049743457, 'reg_lambda': 0.9940469106684195, 'reg_alpha': 0.5373818699901848}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:02:02,792] Trial 37 finished with value: -0.7093251049518585 and parameters: {'learning_rate': 0.27681766195092145, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9571550401309905, 'colsample_bytree': 0.9003779780142579, 'reg_lambda': 0.21595570335997094, 'reg_alpha': 0.3033914214380926}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:03:57,963] Trial 38 finished with value: -0.6791999042034149 and parameters: {'learning_rate': 0.27162831165899787, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9828410622890028, 'colsample_bytree': 0.9443815448674001, 'reg_lambda': 0.6237340434406919, 'reg_alpha': 0.46070838525652974}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:05:37,348] Trial 39 finished with value: -0.7484566569328308 and parameters: {'learning_rate': 0.2798859467675218, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9933202014101475, 'colsample_bytree': 0.9285049216281169, 'reg_lambda': 0.5248699497373881, 'reg_alpha': 0.2249054659498349}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:07:15,706] Trial 40 finished with value: -0.6842408776283264 and parameters: {'learning_rate': 0.2841250441418269, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9378294791932952, 'colsample_bytree': 0.9063592223603023, 'reg_lambda': 0.9095546460683313, 'reg_alpha': 0.3336459488980454}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:09:10,050] Trial 41 finished with value: -0.7152472734451294 and parameters: {'learning_rate': 0.27113148148602656, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9837838597511568, 'colsample_bytree': 0.9442071343397279, 'reg_lambda': 0.6095279426450729, 'reg_alpha': 0.4535352442097307}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:11:03,871] Trial 42 finished with value: -0.736948698759079 and parameters: {'learning_rate': 0.2736112256645023, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9790360982397067, 'colsample_bytree': 0.9552967694015236, 'reg_lambda': 0.7229037156818763, 'reg_alpha': 0.5633015402718814}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:12:58,702] Trial 43 finished with value: -0.7134004533290863 and parameters: {'learning_rate': 0.2649026387373367, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9675485796617158, 'colsample_bytree': 0.9496852631932794, 'reg_lambda': 0.4513030133106263, 'reg_alpha': 0.4196402804212352}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:14:53,027] Trial 44 finished with value: -0.7480067610740662 and parameters: {'learning_rate': 0.26965175253431123, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9874026096896438, 'colsample_bytree': 0.9617608681711529, 'reg_lambda': 0.6520164979356091, 'reg_alpha': 0.2832265474442526}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:16:47,369] Trial 45 finished with value: -0.7337420582771301 and parameters: {'learning_rate': 0.27523816480103375, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9947625366669873, 'colsample_bytree': 0.9940882729666316, 'reg_lambda': 0.8083743435235047, 'reg_alpha': 0.4806835576897271}. Best is trial 16 with value: -0.6097070574760437.\n",
      "[I 2025-01-04 07:18:40,546] Trial 46 finished with value: -0.5529768466949463 and parameters: {'learning_rate': 0.29335241526338074, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9297297900203495, 'colsample_bytree': 0.9209556092679025, 'reg_lambda': 0.7481811256932276, 'reg_alpha': 0.09430875125733879}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:20:19,593] Trial 47 finished with value: -0.6920382082462311 and parameters: {'learning_rate': 0.2924929402747761, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.931836013769819, 'colsample_bytree': 0.9184527596826543, 'reg_lambda': 0.7558816584807727, 'reg_alpha': 0.06366082644179516}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:21:57,749] Trial 48 finished with value: -0.630103200674057 and parameters: {'learning_rate': 0.29701733609499886, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9258914124576398, 'colsample_bytree': 0.927707797318265, 'reg_lambda': 0.9230283512322455, 'reg_alpha': 0.15039865078593723}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:23:36,809] Trial 49 finished with value: -0.7325054705142975 and parameters: {'learning_rate': 0.2957548852753902, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9266874244545259, 'colsample_bytree': 0.9268969059179958, 'reg_lambda': 0.8481113559371116, 'reg_alpha': 0.15407424407041634}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:25:30,563] Trial 50 finished with value: -0.665748119354248 and parameters: {'learning_rate': 0.2996285294629949, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9179365158120802, 'colsample_bytree': 0.9342883683682451, 'reg_lambda': 0.9297749066298522, 'reg_alpha': 0.06051528688558612}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:27:23,554] Trial 51 finished with value: -0.7085631191730499 and parameters: {'learning_rate': 0.29569580319924565, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9141579989431022, 'colsample_bytree': 0.9328064325563061, 'reg_lambda': 0.9420195832820144, 'reg_alpha': 0.08093168187783882}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:29:17,837] Trial 52 finished with value: -0.6892885565757751 and parameters: {'learning_rate': 0.2991413413459486, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9252222791006394, 'colsample_bytree': 0.9169747173786644, 'reg_lambda': 0.9225624760735089, 'reg_alpha': 0.048950391265142564}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:31:11,987] Trial 53 finished with value: -0.7196835577487946 and parameters: {'learning_rate': 0.29997038982722996, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9368741729306043, 'colsample_bytree': 0.9223671490911571, 'reg_lambda': 0.8568176325731895, 'reg_alpha': 0.16329751273306373}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:33:05,554] Trial 54 finished with value: -0.7369715869426727 and parameters: {'learning_rate': 0.2900876932839527, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9190377085438465, 'colsample_bytree': 0.9104655181980106, 'reg_lambda': 0.9977952392638573, 'reg_alpha': 0.11130345599463856}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:34:59,128] Trial 55 finished with value: -0.7152418792247772 and parameters: {'learning_rate': 0.29627606525740074, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9275934898389878, 'colsample_bytree': 0.9370384503952701, 'reg_lambda': 0.9546381923849956, 'reg_alpha': 0.04901483928924884}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:36:38,142] Trial 56 finished with value: -0.6872328221797943 and parameters: {'learning_rate': 0.29417486434685475, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9054628369137394, 'colsample_bytree': 0.9314145008847762, 'reg_lambda': 0.8091148927784017, 'reg_alpha': 0.00761422123644586}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:38:16,491] Trial 57 finished with value: -0.6538741588592529 and parameters: {'learning_rate': 0.29783985562506426, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9111521964541051, 'colsample_bytree': 0.9253248662929741, 'reg_lambda': 0.8945065228747294, 'reg_alpha': 0.18218657278441347}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:39:54,923] Trial 58 finished with value: -0.7454347312450409 and parameters: {'learning_rate': 0.29769693897421967, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9113954806808309, 'colsample_bytree': 0.9275034941666123, 'reg_lambda': 0.894074249669621, 'reg_alpha': 0.17093601940091058}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:41:33,909] Trial 59 finished with value: -0.7019536197185516 and parameters: {'learning_rate': 0.2910725191778204, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9404969715018678, 'colsample_bytree': 0.9810248681740447, 'reg_lambda': 0.7727383341019384, 'reg_alpha': 0.25350580110201737}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:43:13,187] Trial 60 finished with value: -0.667500764131546 and parameters: {'learning_rate': 0.28907647592574903, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9474133294448345, 'colsample_bytree': 0.9045754201232431, 'reg_lambda': 0.8645903873002542, 'reg_alpha': 0.12411403342518712}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:44:51,350] Trial 61 finished with value: -0.7521228045225143 and parameters: {'learning_rate': 0.2920368951543123, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9187175904072563, 'colsample_bytree': 0.9245690116642411, 'reg_lambda': 0.9583479690805393, 'reg_alpha': 0.2187460495074223}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:46:30,690] Trial 62 finished with value: -0.7158040404319763 and parameters: {'learning_rate': 0.29823328666229937, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9152024622389626, 'colsample_bytree': 0.9148103536851432, 'reg_lambda': 0.9183983875890206, 'reg_alpha': 0.12815935511616516}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:48:09,674] Trial 63 finished with value: -0.7025918662548065 and parameters: {'learning_rate': 0.2950035500775117, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9226185448612759, 'colsample_bytree': 0.9406603482299465, 'reg_lambda': 0.8333848423124554, 'reg_alpha': 0.0776249653104666}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:49:48,571] Trial 64 finished with value: -0.6529607474803925 and parameters: {'learning_rate': 0.2972771713273083, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9297766006449264, 'colsample_bytree': 0.920273887696999, 'reg_lambda': 0.32082764280998183, 'reg_alpha': 0.18531005547613114}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:51:27,954] Trial 65 finished with value: -0.7221521139144897 and parameters: {'learning_rate': 0.29327164949141643, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9304838574262022, 'colsample_bytree': 0.9218847485831572, 'reg_lambda': 0.3149042064645399, 'reg_alpha': 0.18193563185220382}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:53:06,244] Trial 66 finished with value: -0.6307300329208374 and parameters: {'learning_rate': 0.2869789312863706, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9008299359732003, 'colsample_bytree': 0.9714086755645387, 'reg_lambda': 0.38944312441666634, 'reg_alpha': 0.3639788024903472}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:54:45,146] Trial 67 finished with value: -0.7019029259681702 and parameters: {'learning_rate': 0.2872303377309677, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9003754118285846, 'colsample_bytree': 0.9694894189643621, 'reg_lambda': 0.35695631999075844, 'reg_alpha': 0.3576002448187733}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:56:24,143] Trial 68 finished with value: -0.6405041515827179 and parameters: {'learning_rate': 0.29049771993174967, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9536039895218986, 'colsample_bytree': 0.9734320206109719, 'reg_lambda': 0.41486818693696764, 'reg_alpha': 0.28833112552666273}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:58:03,148] Trial 69 finished with value: -0.7329035997390747 and parameters: {'learning_rate': 0.28435885597090604, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9532477890217237, 'colsample_bytree': 0.9962078851750854, 'reg_lambda': 0.39720706230491765, 'reg_alpha': 0.3224713905607592}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 07:59:42,475] Trial 70 finished with value: -0.7517499774694443 and parameters: {'learning_rate': 0.2851230903016479, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9599441683912477, 'colsample_bytree': 0.9821063645149269, 'reg_lambda': 0.4215224444912336, 'reg_alpha': 0.3889009730053248}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:01:21,074] Trial 71 finished with value: -0.7133389413356781 and parameters: {'learning_rate': 0.28952981862549093, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9477947892552657, 'colsample_bytree': 0.9767398012382104, 'reg_lambda': 0.48386504228690774, 'reg_alpha': 0.29137639043079966}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:02:59,680] Trial 72 finished with value: -0.7021363973617554 and parameters: {'learning_rate': 0.29088790731053193, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9330952094716329, 'colsample_bytree': 0.9593200224757444, 'reg_lambda': 0.341503577926278, 'reg_alpha': 0.2430837712039884}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:04:38,431] Trial 73 finished with value: -0.7353177666664124 and parameters: {'learning_rate': 0.28661490968335634, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9398713764840894, 'colsample_bytree': 0.9713298182797724, 'reg_lambda': 0.3029914484588579, 'reg_alpha': 0.14034471734655643}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:06:17,176] Trial 74 finished with value: -0.6150960326194763 and parameters: {'learning_rate': 0.2943891063672366, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9440759828527412, 'colsample_bytree': 0.9662671510890986, 'reg_lambda': 0.26267787567462864, 'reg_alpha': 0.2616812559621986}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:07:55,531] Trial 75 finished with value: -0.7431079149246216 and parameters: {'learning_rate': 0.29260515893313643, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9525753018033463, 'colsample_bytree': 0.9649784279170405, 'reg_lambda': 0.1873945677621467, 'reg_alpha': 0.2713381293120205}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:09:34,418] Trial 76 finished with value: -0.6789349913597107 and parameters: {'learning_rate': 0.28769353911150425, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9448901559492897, 'colsample_bytree': 0.9664255680459918, 'reg_lambda': 0.25244234707471536, 'reg_alpha': 0.3158381429629581}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:11:13,213] Trial 77 finished with value: -0.7208278775215149 and parameters: {'learning_rate': 0.29443598332966914, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9358304358843472, 'colsample_bytree': 0.9745429177232331, 'reg_lambda': 0.27248834825818224, 'reg_alpha': 0.4370882012139235}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:12:53,143] Trial 78 finished with value: -0.7177897393703461 and parameters: {'learning_rate': 0.28257465494920714, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9565497817104538, 'colsample_bytree': 0.9501642405694802, 'reg_lambda': 0.5402486963095567, 'reg_alpha': 0.34936063034407977}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:14:32,586] Trial 79 finished with value: -0.7137304842472076 and parameters: {'learning_rate': 0.27728315190310315, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9497163936816496, 'colsample_bytree': 0.9903072228173815, 'reg_lambda': 0.3631504516658836, 'reg_alpha': 0.37637050700702973}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:16:11,865] Trial 80 finished with value: -0.7279497385025024 and parameters: {'learning_rate': 0.2905168702236349, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9415424576391825, 'colsample_bytree': 0.9841048485901027, 'reg_lambda': 0.28553085031406245, 'reg_alpha': 0.40323891638729853}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:17:50,947] Trial 81 finished with value: -0.6815051436424255 and parameters: {'learning_rate': 0.2953743135027043, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9618082910557729, 'colsample_bytree': 0.9788608804370063, 'reg_lambda': 0.4030562637751464, 'reg_alpha': 0.2031914692926851}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:19:29,541] Trial 82 finished with value: -0.7031141817569733 and parameters: {'learning_rate': 0.2966693362469779, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9278243303790051, 'colsample_bytree': 0.9583815275573637, 'reg_lambda': 0.2275660798308995, 'reg_alpha': 0.2502261124446335}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:21:08,353] Trial 83 finished with value: -0.7273678481578827 and parameters: {'learning_rate': 0.2921385616787355, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9386050967377219, 'colsample_bytree': 0.9741042863574787, 'reg_lambda': 0.4518217322399387, 'reg_alpha': 0.10330630631345716}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:22:47,338] Trial 84 finished with value: -0.718252420425415 and parameters: {'learning_rate': 0.2937421050177127, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9345629020332381, 'colsample_bytree': 0.9506459072638499, 'reg_lambda': 0.16815955202632082, 'reg_alpha': 0.22582528940476526}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:24:27,591] Trial 85 finished with value: -0.7357905805110931 and parameters: {'learning_rate': 0.25510466429484346, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9431560492082275, 'colsample_bytree': 0.9672994278259404, 'reg_lambda': 0.47985253524269, 'reg_alpha': 0.496005715614381}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:26:05,922] Trial 86 finished with value: -0.7092383801937103 and parameters: {'learning_rate': 0.2886246368681798, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9296043009121046, 'colsample_bytree': 0.9114282971256651, 'reg_lambda': 0.4238335768417741, 'reg_alpha': 0.2851314712171271}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:27:44,713] Trial 87 finished with value: -0.7244008183479309 and parameters: {'learning_rate': 0.2912840280316531, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9213700259097956, 'colsample_bytree': 0.9203891465866928, 'reg_lambda': 0.3710638995702899, 'reg_alpha': 0.3363247330923925}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:29:23,265] Trial 88 finished with value: -0.6854396760463715 and parameters: {'learning_rate': 0.2807644880551239, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9553544515034171, 'colsample_bytree': 0.9079721353565094, 'reg_lambda': 0.5126511119660464, 'reg_alpha': 0.09135933902306477}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:31:03,287] Trial 89 finished with value: -0.6845428049564362 and parameters: {'learning_rate': 0.2681378534754991, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.946953878561248, 'colsample_bytree': 0.9163911562098376, 'reg_lambda': 0.33864277034612816, 'reg_alpha': 0.1887298856971069}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:32:42,531] Trial 90 finished with value: -0.7307668924331665 and parameters: {'learning_rate': 0.2742538771849894, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9700814401364984, 'colsample_bytree': 0.9527762747055665, 'reg_lambda': 0.6960518993768058, 'reg_alpha': 0.14834872916512473}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:34:21,410] Trial 91 finished with value: -0.7241732478141785 and parameters: {'learning_rate': 0.29788111348479884, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9056148438261717, 'colsample_bytree': 0.9244522063352639, 'reg_lambda': 0.29549319559893245, 'reg_alpha': 0.21514171758971595}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:35:59,958] Trial 92 finished with value: -0.7382765710353851 and parameters: {'learning_rate': 0.2984036532423238, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9000765076438713, 'colsample_bytree': 0.9709085716641236, 'reg_lambda': 0.9758469515251084, 'reg_alpha': 0.1862239462725403}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:37:38,888] Trial 93 finished with value: -0.747880220413208 and parameters: {'learning_rate': 0.29605728276654414, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9091272221765627, 'colsample_bytree': 0.9262105276829217, 'reg_lambda': 0.8885757834705211, 'reg_alpha': 0.26705296373373494}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:39:18,027] Trial 94 finished with value: -0.7056885063648224 and parameters: {'learning_rate': 0.296919567156521, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.907750946864483, 'colsample_bytree': 0.9294562749865749, 'reg_lambda': 0.2354692166061845, 'reg_alpha': 0.15154942894583173}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:40:56,846] Trial 95 finished with value: -0.7079083025455475 and parameters: {'learning_rate': 0.2930200941294018, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9031759611282628, 'colsample_bytree': 0.9899672421907284, 'reg_lambda': 0.5650287730927082, 'reg_alpha': 0.30465865312944795}. Best is trial 46 with value: -0.5529768466949463.\n",
      "[I 2025-01-04 08:42:35,901] Trial 96 finished with value: -0.4639127850532532 and parameters: {'learning_rate': 0.2944419254747207, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.911247280730723, 'colsample_bytree': 0.9191254559427142, 'reg_lambda': 0.3893495715451757, 'reg_alpha': 0.5290172006768908}. Best is trial 96 with value: -0.4639127850532532.\n",
      "[I 2025-01-04 08:44:15,421] Trial 97 finished with value: -0.7053947746753693 and parameters: {'learning_rate': 0.29484796724702544, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9252358124647873, 'colsample_bytree': 0.9185165828745704, 'reg_lambda': 0.322494925661826, 'reg_alpha': 0.5304960936297385}. Best is trial 96 with value: -0.4639127850532532.\n",
      "[I 2025-01-04 08:45:54,254] Trial 98 finished with value: -0.6380625665187836 and parameters: {'learning_rate': 0.2940279430339689, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9140484017975031, 'colsample_bytree': 0.9134467366314295, 'reg_lambda': 0.39107821624288686, 'reg_alpha': 0.6206277281314003}. Best is trial 96 with value: -0.4639127850532532.\n",
      "[I 2025-01-04 08:47:32,490] Trial 99 finished with value: -0.7340511679649353 and parameters: {'learning_rate': 0.28987717294659465, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9138830482523722, 'colsample_bytree': 0.9140392890205016, 'reg_lambda': 0.3948369191773436, 'reg_alpha': 0.5963761022644105}. Best is trial 96 with value: -0.4639127850532532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model with optimized hyperparameters...\n",
      "Final model saved successfully!\n",
      "Evaluating on test data...\n",
      "Final Weighted R² Score: 0.7251\n"
     ]
    }
   ],
   "source": [
    "import polars as pl  #optuna hyperparameter tuning\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Weighted R² evaluation metric\n",
    "def weighted_r2_score(y_true, y_pred, weights):\n",
    "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "    denominator = np.sum(weights * y_true ** 2)\n",
    "    r2 = 1 - (numerator / denominator)\n",
    "    return r2\n",
    "\n",
    "# Step 1: Load Parquet Files\n",
    "train_path = \"/home/jupyter/data/external_memory_train.parquet\"\n",
    "test_path = \"/home/jupyter/data/external_memory_test.parquet\"\n",
    "\n",
    "print(\"Loading Parquet datasets for external memory usage...\")\n",
    "train_data = pl.read_parquet(train_path)\n",
    "test_data = pl.read_parquet(test_path)\n",
    "\n",
    "# Step 2: Prepare DMatrix with Parquet using Explicit Labels and Weights\n",
    "X_train = train_data.select(pl.exclude([\"responder_6\", \"weight\", \"date_id\", \"time_id\"])).to_numpy()\n",
    "y_train = train_data[\"responder_6\"].to_numpy()\n",
    "train_weights = train_data[\"weight\"].to_numpy()\n",
    "\n",
    "X_test = test_data.select(pl.exclude([\"responder_6\", \"weight\", \"date_id\", \"time_id\"])).to_numpy()\n",
    "y_test = test_data[\"responder_6\"].to_numpy()\n",
    "test_weights = test_data[\"weight\"].to_numpy()\n",
    "\n",
    "# Explicitly define DMatrix using numpy arrays\n",
    "dtrain_ext = xgb.DMatrix(X_train, label=y_train, weight=train_weights)\n",
    "dtest_ext = xgb.DMatrix(X_test, label=y_test, weight=test_weights)\n",
    "\n",
    "# Checkpoint path for Optuna study\n",
    "optuna_checkpoint = \"/home/jupyter/data/optuna_study.pkl\"\n",
    "\n",
    "# Step 3: Define the Optuna Objective Function for Hyperparameter Optimization with Chunking and Regularization\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.25, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 8, 9),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.9, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.9, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 1.0),\n",
    "        \"device\": \"cuda\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "    batch_size = 10\n",
    "    num_boost_round = 100\n",
    "    model = None\n",
    "    for i in range(0, num_boost_round, batch_size):\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain_ext,\n",
    "            num_boost_round=batch_size,\n",
    "            xgb_model=model if i > 0 else None\n",
    "        )\n",
    "\n",
    "    # Evaluate Performance on Test Data\n",
    "    y_pred = model.predict(dtest_ext)\n",
    "    return -weighted_r2_score(y_test, y_pred, test_weights)\n",
    "\n",
    "# Step 4: Check for existing Optuna checkpoint\n",
    "if os.path.exists(optuna_checkpoint):\n",
    "    print(\"Resuming existing Optuna study...\")\n",
    "    with open(optuna_checkpoint, \"rb\") as f:\n",
    "        study = pickle.load(f)\n",
    "else:\n",
    "    print(\"Creating new Optuna study...\")\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Step 5: Run Bayesian Hyperparameter Optimization with Optuna\n",
    "try:\n",
    "    print(\"Running Bayesian optimization with Optuna...\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    with open(optuna_checkpoint, \"wb\") as f:\n",
    "        pickle.dump(study, f)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted. Saving current progress...\")\n",
    "    with open(optuna_checkpoint, \"wb\") as f:\n",
    "        pickle.dump(study, f)\n",
    "    raise\n",
    "\n",
    "# Step 6: Train Final Model with Optimized Hyperparameters Using Chunking\n",
    "print(\"Training final model with optimized hyperparameters...\")\n",
    "best_params = study.best_params\n",
    "batch_size = 10\n",
    "num_boost_round = 100\n",
    "final_model = None\n",
    "for i in range(0, num_boost_round, batch_size):\n",
    "    final_model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain_ext,\n",
    "        num_boost_round=batch_size,\n",
    "        xgb_model=final_model if i > 0 else None\n",
    "    )\n",
    "\n",
    "# Step 7: Save Final Model\n",
    "final_model.save_model(\"/home/jupyter/data/final_xgboost_model.json\")\n",
    "print(\"Final model saved successfully!\")\n",
    "\n",
    "# Step 8: Evaluate Final Model\n",
    "print(\"Evaluating on test data...\")\n",
    "y_pred = final_model.predict(dtest_ext)\n",
    "final_r2 = weighted_r2_score(y_test, y_pred, test_weights)\n",
    "print(f\"Final Weighted R² Score: {final_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d946011a-cfa9-463a-a617-486c42175f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row_id', 'date_id', 'time_id', 'symbol_id', 'weight', 'is_scored', 'feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78']\n"
     ]
    }
   ],
   "source": [
    "test_data = pl.read_parquet('/home/jupyter/data/jane-street/test.parquet')\n",
    "print(test_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49c7e64-add7-4d07-81d2-0a4688dab0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model and metadata...\n",
      "Loading test data...\n",
      "Aligning test data with 30 model features...\n"
     ]
    },
    {
     "ename": "ColumnNotFoundError",
     "evalue": "responder_0\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'select' <---\nDF [\"row_id\", \"date_id\", \"time_id\", \"symbol_id\"]; PROJECT */325 COLUMNS; SELECTION: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_columns:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAligning test data with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(feature_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m \u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature columns were not found in the metadata. Cannot proceed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/dataframe/frame.py:9113\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   9013\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\n\u001b[1;32m   9014\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr\n\u001b[1;32m   9015\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   9017\u001b[0m \u001b[38;5;124;03m    Select columns from this DataFrame.\u001b[39;00m\n\u001b[1;32m   9018\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9111\u001b[0m \u001b[38;5;124;03m    └──────────────┘\u001b[39;00m\n\u001b[1;32m   9112\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 9113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/lazyframe/frame.py:2029\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2028\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: responder_0\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'select' <---\nDF [\"row_id\", \"date_id\", \"time_id\", \"symbol_id\"]; PROJECT */325 COLUMNS; SELECTION: None"
     ]
    }
   ],
   "source": [
    "#test against train.parquet provided in competition\n",
    "\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "# Step 1: Load the Pre-trained Model and Feature Names\n",
    "print(\"Loading pre-trained model and metadata...\")\n",
    "model = xgb.Booster()\n",
    "model.load_model(\"/home/jupyter/data/final_xgboost_model.json\")\n",
    "\n",
    "# Load saved feature names and best parameters for alignment\n",
    "with open(\"/home/jupyter/data/final_model_metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "    feature_columns = metadata[\"feature_names\"]\n",
    "\n",
    "# Step 2: Load the Test Set\n",
    "print(\"Loading test data...\")\n",
    "test_data = pl.read_parquet('/home/jupyter/data/jane-street/test.parquet')\n",
    "\n",
    "# Step 3: Feature Engineering (Ensure Consistency with Training)\n",
    "exclude_columns = ['date_id', 'time_id', 'symbol_id', 'weight', 'partition_id', 'responder_6']\n",
    "\n",
    "# Remove boolean columns for feature engineering consistency\n",
    "numerical_columns = [\n",
    "    col for col in test_data.columns \n",
    "    if col not in exclude_columns and test_data[col].dtype != pl.Boolean\n",
    "]\n",
    "\n",
    "# Generate Lagged Features\n",
    "for feature in numerical_columns:\n",
    "    test_data = test_data.with_columns(\n",
    "        pl.col(feature).shift(1).over(\"symbol_id\").alias(f\"{feature}_lag_1\")\n",
    "    )\n",
    "\n",
    "# Generate Difference Features\n",
    "for feature in numerical_columns:\n",
    "    test_data = test_data.with_columns(\n",
    "        (pl.col(feature).cast(pl.Float64) - pl.col(f'{feature}_lag_1').cast(pl.Float64))\n",
    "        .alias(f'{feature}_lag_diff_1')\n",
    "    )\n",
    "\n",
    "# Generate Ratio Features\n",
    "for feature in numerical_columns:\n",
    "    test_data = test_data.with_columns(\n",
    "        (pl.col(feature).cast(pl.Float64) / (pl.col(f'{feature}_lag_1').cast(pl.Float64) + 1e-9))\n",
    "        .alias(f'{feature}_lag_ratio_1')\n",
    "    )\n",
    "\n",
    "# Step 4: Handle Missing Values (Fill Nulls After Feature Engineering)\n",
    "test_data = test_data.fill_null(0)\n",
    "\n",
    "# ✅ **Step 5: Align Features with Model's Trained Features**\n",
    "# Ensure test data has the exact columns used during training\n",
    "if feature_columns:\n",
    "    print(f\"Aligning test data with {len(feature_columns)} model features...\")\n",
    "    test_data = test_data.select(feature_columns)\n",
    "else:\n",
    "    raise ValueError(\"Feature columns were not found in the metadata. Cannot proceed.\")\n",
    "\n",
    "# Convert the test data into a DMatrix using the same feature order\n",
    "X_test = test_data.to_numpy()\n",
    "dtest = xgb.DMatrix(X_test, feature_names=feature_columns)\n",
    "\n",
    "# Step 6: Make Predictions\n",
    "print(\"Making predictions...\")\n",
    "predictions = model.predict(dtest)\n",
    "\n",
    "# Step 7: Add Predictions to the DataFrame\n",
    "test_data = test_data.with_columns(\n",
    "    pl.Series(name=\"prediction\", values=predictions)\n",
    ")\n",
    "\n",
    "# Step 8: Prepare the Submission File (CSV)\n",
    "submission = test_data.select([\"date_id\", \"symbol_id\", \"prediction\"])\n",
    "submission.write_csv(\"/home/jupyter/data/submission.csv\")\n",
    "print(\"Submission file created successfully!\")\n",
    "\n",
    "# ✅ Final Check\n",
    "print(\"Predictions successfully made and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee79d1ca-be3f-44ca-bbab-bc25a1e85069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Weighted R² Score (CV): 0.8823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate_with_chunking(X, y, weights, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        weights_train, weights_val = weights[train_idx], weights[val_idx]\n",
    "\n",
    "        # Convert to DMatrix\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, weight=weights_train)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val, weight=weights_val)\n",
    "\n",
    "        # Train with the best parameters from Optuna\n",
    "        model = xgb.train(best_params, dtrain, num_boost_round=100)\n",
    "        \n",
    "        # Predict and score\n",
    "        y_pred = model.predict(dval)\n",
    "        score = weighted_r2_score(y_val, y_pred, weights_val)\n",
    "        scores.append(score)\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "    print(f\"Average Weighted R² Score (CV): {avg_score:.4f}\")\n",
    "\n",
    "# Run the cross-validation\n",
    "cross_validate_with_chunking(X_train, y_train, train_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b018a12-01df-44c7-8a6c-220b7026876d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
