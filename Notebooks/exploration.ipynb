{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import dask.dataframe as dd\n\n# Load the dataset in Dask (memory-efficient)\ndata_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet'\ntrain_data = dd.read_parquet(data_path)\n\n# Take a 10% random sample of the data for initial inspection\nsample_data = train_data.sample(frac=0.1, random_state=42).compute()  # Converts to pandas\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Check the first few rows of the sample\n#print(sample_data.head())\n\n# Check the data types of each column\nprint(sample_data.dtypes)\n\n# Get general information about the data, including non-null counts\n#print(sample_data.info())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the total number of rows (compute once for efficiency)\ntotal_rows = len(train_data)\n\n# Count missing values in each column\nmissing_values = train_data.isna().sum().compute()  # .compute() to get concrete values in pandas\n\n# Identify columns where the count of NaNs is equal to the total number of rows\nall_nan_columns = missing_values[missing_values == total_rows].index\nprint(\"Columns with all NaN values:\", all_nan_columns.tolist())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#test what percent of each column is filled with NaN values\n#will hopefully help determine which ones are causing the fill NaN error\n\nimport pandas as pd\n\n# Calculate NaN percentages\nnan_percentage = train_data.isna().mean().compute() * 100  # Compute to get concrete values in pandas\n\n# Sort columns by NaN percentage in descending order (highest NaN percentage at the top)\nnan_percentage_sorted = nan_percentage.sort_values(ascending=False)\n\n# Display all columns with NaN percentages\npd.set_option('display.max_rows', None)  # Show all rows without truncation\nprint(\"NaN percentage per column (sorted):\\n\", nan_percentage_sorted)\npd.reset_option('display.max_rows')  # Reset display option back to default\n\n'''\nNaN percentage per column (sorted):\n feature_26      17.900406\nfeature_21      17.900406\nfeature_27      17.900406\nfeature_31      17.900406\nfeature_42       9.125593\nfeature_39       9.125593\nfeature_50       9.026816\nfeature_53       9.026816\nfeature_00       6.752030\nfeature_01       6.752030\nfeature_02       6.752030\nfeature_03       6.752030\nfeature_04       6.752030\nfeature_15       2.566024\nfeature_41       2.319274\nfeature_44       2.319274\nfeature_52       2.217180\nfeature_55       2.217180\nfeature_74       1.026493\nfeature_73       1.026493\n'''\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Count missing values in each column\nmissing_values = sample_data.isna().sum()\nprint(\"Missing values per column:\\n\", missing_values)\n\n# Show only columns with missing values for better clarity\nmissing_columns = missing_values[missing_values > 0]\nprint(\"Columns with missing values:\\n\", missing_columns)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter to exclude the first 85 days\nsample_data = sample_data[sample_data['date_id'] >= 85]\nprint(\"Data after filtering the first 85 days:\", sample_data.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply backward-fill, then forward-fill\nsample_data = sample_data.bfill().ffill()\n\n# Verify that there are no remaining missing values\nprint(\"Remaining missing values:\", sample_data.isna().sum().sum())  # Should be 0 if all NaNs are filled\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Refined code to avoid sampling dataset, instead applying operations directly and finishing up.\n\nimport dask.dataframe as dd\n\n# Load the entire dataset with Dask\ntrain_data = dd.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet')\n\n# Filter out the first 85 days\ntrain_data = train_data[train_data['date_id'] >= 85]\n# Step 1: Drop fully empty (all-NaN) partitions to save memory\ndef drop_empty_partitions(df):\n    return df.dropna(how='all')\n\ntrain_data = train_data.map_partitions(drop_empty_partitions)\n\n# Step 2: Apply fillna with a limit to handle short gaps but retain larger missing sections\ntrain_data = train_data.bfill(limit=5000).ffill(limit=5000)\n\n# Step 3: Sample 10% of the data to compute medians\nsample_data = train_data.sample(frac=0.1).compute()\n\n# Select only numeric columns\nnumeric_columns = sample_data.select_dtypes(include=['number'])\nmedians = numeric_columns.median()\n\n# Step 4: Fill remaining NaNs using column-specific medians\ntrain_data = train_data.fillna(medians.to_dict())\n\n# Optional: Check for remaining NaNs if needed\nremaining_na = train_data.isna().sum().sum().compute()\nprint(\"Remaining NaNs after fill:\", remaining_na)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T05:50:41.631994Z","iopub.execute_input":"2024-11-15T05:50:41.632602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}