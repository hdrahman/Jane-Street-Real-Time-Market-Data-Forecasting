{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import dask.dataframe as dd\n\n# Load the dataset in Dask (memory-efficient)\ndata_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet'\ntrain_data = dd.read_parquet(data_path)\n\n# Take a 10% random sample of the data for initial inspection\nsample_data = train_data.sample(frac=0.1, random_state=42).compute()  # Converts to pandas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T05:01:13.442800Z","iopub.execute_input":"2024-11-14T05:01:13.443297Z","iopub.status.idle":"2024-11-14T05:02:11.961015Z","shell.execute_reply.started":"2024-11-14T05:01:13.443250Z","shell.execute_reply":"2024-11-14T05:02:11.955984Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Check the first few rows of the sample\nprint(sample_data.head())\n\n# Check the data types of each column\nprint(sample_data.dtypes)\n\n# Get general information about the data, including non-null counts\nprint(sample_data.info())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T05:02:11.972704Z","iopub.execute_input":"2024-11-14T05:02:11.978884Z","iopub.status.idle":"2024-11-14T05:02:12.124922Z","shell.execute_reply.started":"2024-11-14T05:02:11.978603Z","shell.execute_reply":"2024-11-14T05:02:12.119258Z"}},"outputs":[{"name":"stdout","text":"        date_id  time_id  symbol_id    weight  feature_00  feature_01  \\\n587075       65      332         38  1.351800         NaN         NaN   \n757733       81      813         19  3.195052         NaN         NaN   \n172256       21      503         10  1.109825         NaN         NaN   \n757596       81      802         10  1.189921         NaN         NaN   \n650440       71        8          8  1.632438         NaN         NaN   \n\n        feature_02  feature_03  feature_04  feature_05  ...  responder_0  \\\n587075         NaN         NaN         NaN    0.315594  ...     0.256910   \n757733         NaN         NaN         NaN   -1.569358  ...    -0.098848   \n172256         NaN         NaN         NaN   -0.064054  ...     0.202636   \n757596         NaN         NaN         NaN   -1.472570  ...     2.127164   \n650440         NaN         NaN         NaN    0.621679  ...    -0.428931   \n\n        responder_1  responder_2  responder_3  responder_4  responder_5  \\\n587075    -0.082456    -0.040593    -3.491451    -1.697017    -5.000000   \n757733     0.535817    -0.082651     0.293387     1.004242     0.437111   \n172256     0.128824    -0.148082    -0.341684     1.437995    -0.534279   \n757596    -0.203588     3.755299     2.740224     1.904249     5.000000   \n650440    -0.603211    -0.402254     3.902206     3.245628     0.745335   \n\n        responder_6  responder_7  responder_8  partition_id  \n587075    -0.449624    -0.382103     0.003017             0  \n757733     0.453235     0.184523     0.736464             0  \n172256    -0.598404     0.842790    -0.760445             0  \n757596     1.053998     1.170140     1.893582             0  \n650440     5.000000     4.203393     1.750816             0  \n\n[5 rows x 93 columns]\ndate_id            int16\ntime_id            int16\nsymbol_id           int8\nweight           float32\nfeature_00       float32\n                  ...   \nresponder_5      float32\nresponder_6      float32\nresponder_7      float32\nresponder_8      float32\npartition_id    category\nLength: 93, dtype: object\n<class 'pandas.core.frame.DataFrame'>\nIndex: 4712723 entries, 587075 to 57440\nData columns (total 93 columns):\n #   Column        Dtype   \n---  ------        -----   \n 0   date_id       int16   \n 1   time_id       int16   \n 2   symbol_id     int8    \n 3   weight        float32 \n 4   feature_00    float32 \n 5   feature_01    float32 \n 6   feature_02    float32 \n 7   feature_03    float32 \n 8   feature_04    float32 \n 9   feature_05    float32 \n 10  feature_06    float32 \n 11  feature_07    float32 \n 12  feature_08    float32 \n 13  feature_09    int8    \n 14  feature_10    int8    \n 15  feature_11    int16   \n 16  feature_12    float32 \n 17  feature_13    float32 \n 18  feature_14    float32 \n 19  feature_15    float32 \n 20  feature_16    float32 \n 21  feature_17    float32 \n 22  feature_18    float32 \n 23  feature_19    float32 \n 24  feature_20    float32 \n 25  feature_21    float32 \n 26  feature_22    float32 \n 27  feature_23    float32 \n 28  feature_24    float32 \n 29  feature_25    float32 \n 30  feature_26    float32 \n 31  feature_27    float32 \n 32  feature_28    float32 \n 33  feature_29    float32 \n 34  feature_30    float32 \n 35  feature_31    float32 \n 36  feature_32    float32 \n 37  feature_33    float32 \n 38  feature_34    float32 \n 39  feature_35    float32 \n 40  feature_36    float32 \n 41  feature_37    float32 \n 42  feature_38    float32 \n 43  feature_39    float32 \n 44  feature_40    float32 \n 45  feature_41    float32 \n 46  feature_42    float32 \n 47  feature_43    float32 \n 48  feature_44    float32 \n 49  feature_45    float32 \n 50  feature_46    float32 \n 51  feature_47    float32 \n 52  feature_48    float32 \n 53  feature_49    float32 \n 54  feature_50    float32 \n 55  feature_51    float32 \n 56  feature_52    float32 \n 57  feature_53    float32 \n 58  feature_54    float32 \n 59  feature_55    float32 \n 60  feature_56    float32 \n 61  feature_57    float32 \n 62  feature_58    float32 \n 63  feature_59    float32 \n 64  feature_60    float32 \n 65  feature_61    float32 \n 66  feature_62    float32 \n 67  feature_63    float32 \n 68  feature_64    float32 \n 69  feature_65    float32 \n 70  feature_66    float32 \n 71  feature_67    float32 \n 72  feature_68    float32 \n 73  feature_69    float32 \n 74  feature_70    float32 \n 75  feature_71    float32 \n 76  feature_72    float32 \n 77  feature_73    float32 \n 78  feature_74    float32 \n 79  feature_75    float32 \n 80  feature_76    float32 \n 81  feature_77    float32 \n 82  feature_78    float32 \n 83  responder_0   float32 \n 84  responder_1   float32 \n 85  responder_2   float32 \n 86  responder_3   float32 \n 87  responder_4   float32 \n 88  responder_5   float32 \n 89  responder_6   float32 \n 90  responder_7   float32 \n 91  responder_8   float32 \n 92  partition_id  category\ndtypes: category(1), float32(86), int16(3), int8(3)\nmemory usage: 1.6 GB\nNone\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Count missing values in each column\nmissing_values = sample_data.isna().sum()\nprint(\"Missing values per column:\\n\", missing_values)\n\n# Show only columns with missing values for better clarity\nmissing_columns = missing_values[missing_values > 0]\nprint(\"Columns with missing values:\\n\", missing_columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T05:02:12.131219Z","iopub.execute_input":"2024-11-14T05:02:12.134087Z","iopub.status.idle":"2024-11-14T05:02:13.508819Z","shell.execute_reply.started":"2024-11-14T05:02:12.133507Z","shell.execute_reply":"2024-11-14T05:02:13.502269Z"}},"outputs":[{"name":"stdout","text":"Missing values per column:\n date_id              0\ntime_id              0\nsymbol_id            0\nweight               0\nfeature_00      318231\n                 ...  \nresponder_5          0\nresponder_6          0\nresponder_7          0\nresponder_8          0\npartition_id         0\nLength: 93, dtype: int64\nColumns with missing values:\n feature_00    318231\nfeature_01    318231\nfeature_02    318231\nfeature_03    318231\nfeature_04    318231\nfeature_08     29889\nfeature_15    120995\nfeature_16        17\nfeature_17     20035\nfeature_18        14\nfeature_19        14\nfeature_21    843597\nfeature_26    843597\nfeature_27    843597\nfeature_31    843597\nfeature_32     47846\nfeature_33     47846\nfeature_37        94\nfeature_39    430378\nfeature_40      6782\nfeature_41    109176\nfeature_42    430378\nfeature_43      6782\nfeature_44    109176\nfeature_45     31506\nfeature_46     31506\nfeature_47        12\nfeature_50    425744\nfeature_51      1408\nfeature_52    104421\nfeature_53    425744\nfeature_54      1408\nfeature_55    104421\nfeature_56        14\nfeature_57        14\nfeature_58     47845\nfeature_62     29059\nfeature_63     22495\nfeature_64     23529\nfeature_65     31506\nfeature_66     31506\nfeature_73     48398\nfeature_74     48398\nfeature_75      5893\nfeature_76      5893\nfeature_77      2000\nfeature_78      2000\ndtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Filter to exclude the first 85 days\nsample_data = sample_data[sample_data['date_id'] >= 85]\nprint(\"Data after filtering the first 85 days:\", sample_data.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T05:02:13.520651Z","iopub.execute_input":"2024-11-14T05:02:13.523199Z","iopub.status.idle":"2024-11-14T05:02:15.846996Z","shell.execute_reply.started":"2024-11-14T05:02:13.522959Z","shell.execute_reply":"2024-11-14T05:02:15.841481Z"}},"outputs":[{"name":"stdout","text":"Data after filtering the first 85 days: (4633309, 93)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Apply backward-fill, then forward-fill\nsample_data = sample_data.bfill().ffill()\n\n# Verify that there are no remaining missing values\nprint(\"Remaining missing values:\", sample_data.isna().sum().sum())  # Should be 0 if all NaNs are filled\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T05:02:15.857182Z","iopub.execute_input":"2024-11-14T05:02:15.857980Z","iopub.status.idle":"2024-11-14T05:02:34.989081Z","shell.execute_reply.started":"2024-11-14T05:02:15.857879Z","shell.execute_reply":"2024-11-14T05:02:34.987347Z"}},"outputs":[{"name":"stdout","text":"Remaining missing values: 0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"''' Refined code to avoid sampling dataset, instead applying operations directly and finishing up.\n\nimport dask.dataframe as dd\n\n# Load the entire dataset with Dask\ntrain_data = dd.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet')\n\n# Filter out the first 85 days\ntrain_data = train_data[train_data['date_id'] >= 85]\n\n# Apply backward-fill and forward-fill to handle NaN values\ntrain_data = train_data.bfill().ffill()\n'''\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T05:02:34.991154Z","iopub.execute_input":"2024-11-14T05:02:34.991627Z","iopub.status.idle":"2024-11-14T05:02:35.003830Z","shell.execute_reply.started":"2024-11-14T05:02:34.991583Z","shell.execute_reply":"2024-11-14T05:02:35.002347Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"\" Refined code to avoid sampling dataset, instead applying operations directly and finishing up.\\n\\nimport dask.dataframe as dd\\n\\n# Load the entire dataset with Dask\\ntrain_data = dd.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet')\\n\\n# Filter out the first 85 days\\ntrain_data = train_data[train_data['date_id'] >= 85]\\n\\n# Apply backward-fill and forward-fill to handle NaN values\\ntrain_data = train_data.bfill().ffill()\\n\""},"metadata":{}}],"execution_count":6}]}